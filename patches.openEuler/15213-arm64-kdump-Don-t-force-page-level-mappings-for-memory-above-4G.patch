From 243d897cbad39574fd516bfc2ce85f2a4d94df5f Mon Sep 17 00:00:00 2001
From: Zhen Lei <thunder.leizhen@huawei.com>
Date: Wed, 27 Apr 2022 18:48:34 +0800
Subject: [PATCH] arm64: kdump: Don't force page-level mappings for memory
 above 4G
Patch-mainline: Not yet, from openEuler
References: bsn#22
openEuler-commit: 243d897cbad39574fd516bfc2ce85f2a4d94df5f
Modified-by-SEL: Yes, modified due to different context


hulk inclusion
category: bugfix
bugzilla: https://gitee.com/openeuler/kernel/issues/I545H8
CVE: NA

-------------------------------------------------------------------------

If the crashkernel reservation is deferred, such boundaries are not known
when the linear mapping is created. But its upper limit is fixed, cannot
above 4G. Therefore, unless otherwise required, block mapping should be
used for memory above 4G to improve performance.

Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
Reviewed-by: Kefeng Wang <wangkefeng.wang@huawei.com>
Signed-off-by: Zheng Zengkai <zhengzengkai@huawei.com>
Signed-off-by: Guoqing Jiang <guoqing.jiang@suse.com>
---
 arch/arm64/mm/mmu.c |   27 +++++++++++++++++++++++++--
 1 file changed, 25 insertions(+), 2 deletions(-)

--- a/arch/arm64/mm/mmu.c
+++ b/arch/arm64/mm/mmu.c
@@ -498,7 +498,7 @@ static void __init map_mem(pgd_t *pgdp)
 	phys_addr_t kernel_start = __pa_symbol(_stext);
 	phys_addr_t kernel_end = __pa_symbol(__init_begin);
 	phys_addr_t start, end;
-	int flags = 0;
+	int flags = 0, eflags = 0;
 	u64 i;
 
 	if (rodata_full || debug_pagealloc_enabled())
@@ -523,17 +523,40 @@ static void __init map_mem(pgd_t *pgdp)
 	}
 #endif
 
+#ifdef CONFIG_KEXEC_CORE
+	if (crash_mem_map)
+		eflags = NO_BLOCK_MAPPINGS | NO_CONT_MAPPINGS;
+#endif
+
 	/* map all the memory banks */
 	for_each_mem_range(i, &start, &end) {
 		if (start >= end)
 			break;
+
+#ifdef CONFIG_KEXEC_CORE
+		if (eflags && (end >= SZ_4G)) {
+			/*
+			 * The memory block cross the 4G boundary.
+			 * Forcibly use page-level mappings for memory under 4G.
+			 */
+			if (start < SZ_4G) {
+				__map_memblock(pgdp, start, SZ_4G - 1,
+					       pgprot_tagged(PAGE_KERNEL), flags | eflags);
+				start  = SZ_4G;
+			}
+
+			/* Page-level mappings is not mandatory for memory above 4G */
+			eflags = 0;
+		}
+#endif
+
 		/*
 		 * The linear map must allow allocation tags reading/writing
 		 * if MTE is present. Otherwise, it has the same attributes as
 		 * PAGE_KERNEL.
 		 */
 		__map_memblock(pgdp, start, end, pgprot_tagged(PAGE_KERNEL),
-			       flags);
+			       flags | eflags);
 	}
 
 	/*
