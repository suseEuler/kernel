From 51f84117e775e3ebe41e680952c2803115a79412 Mon Sep 17 00:00:00 2001
From: Chen Hui <judy.chenhui@huawei.com>
Date: Fri, 25 Nov 2022 12:03:57 +0800
Subject: [PATCH] sched: programmable: Add a tag for the task group
Patch-mainline: Not yet, from openEuler
References: bsn#22
openEuler-commit: 51f84117e775e3ebe41e680952c2803115a79412
Modified-by-SEL: No


hulk inclusion
category: feature
bugzilla: https://gitee.com/openeuler/kernel/issues/I5KUFB
CVE: NA

--------------------------------

Add a tag for the task group, to support the tag-based
scheduling mechanism.

The tag is used to identify a special task or a type of
special tasks, there are many special tasks in the real
world, such as foreground and background tasks, online
and offline tasks, ect. so, we can identify such special
tasks, and execute specific policies.

Signed-off-by: Chen Hui <judy.chenhui@huawei.com>
Signed-off-by: Ren Zhijie <renzhijie2@huawei.com>
Signed-off-by: Hui Tang <tanghui20@huawei.com>
Signed-off-by: Guoqing Jiang <guoqing.jiang@suse.com>
---
 kernel/sched/core.c  | 19 +++++++++++++++++++
 kernel/sched/sched.h |  5 +++++
 2 files changed, 24 insertions(+)

diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 2c30aceed1e9..3e22147307e4 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -8603,6 +8603,13 @@ static void sched_free_group(struct task_group *tg)
 	kmem_cache_free(task_group_cache, tg);
 }
 
+#ifdef CONFIG_BPF_SCHED
+static inline void tg_init_tag(struct task_group *tg, struct task_group *ptg)
+{
+	tg->tag = ptg->tag;
+}
+#endif
+
 /* allocate runqueue etc for a new task group */
 struct task_group *sched_create_group(struct task_group *parent)
 {
@@ -8623,6 +8630,10 @@ struct task_group *sched_create_group(struct task_group *parent)
 	if (!alloc_rt_sched_group(tg, parent))
 		goto err;
 
+#ifdef CONFIG_BPF_SCHED
+	tg_init_tag(tg, parent);
+#endif
+
 	alloc_uclamp_sched_group(tg, parent);
 
 	return tg;
@@ -8694,6 +8705,14 @@ static void sched_change_group(struct task_struct *tsk, int type)
 	sched_change_qos_group(tsk, tg);
 #endif
 
+#ifdef CONFIG_BPF_SCHED
+	/*
+	 * This function has cleared and restored the task status,
+	 * so we do not need to dequeue and enqueue the task again.
+	 */
+	tsk->tag = tg->tag;
+#endif
+
 #ifdef CONFIG_FAIR_GROUP_SCHED
 	if (tsk->sched_class->task_change_group)
 		tsk->sched_class->task_change_group(tsk, type);
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index ad00ba5f6d82..49a10a4bd54c 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -454,7 +454,12 @@ struct task_group {
 	struct uclamp_se	uclamp[UCLAMP_CNT];
 #endif
 
+#ifdef CONFIG_BPF_SCHED
+	/* Used to pad the tag of a group */
+	KABI_USE(1, long tag)
+#else
 	KABI_RESERVE(1)
+#endif
 	KABI_RESERVE(2)
 	KABI_RESERVE(3)
 	KABI_RESERVE(4)
-- 
2.33.0

